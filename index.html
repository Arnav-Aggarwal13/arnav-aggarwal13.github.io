<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Arnav Aggarwal</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <style>
    /* ---------- Layout + base styles ---------- */
    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      padding: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", system-ui, sans-serif;
      line-height: 1.6;
      background: #fafafa;
      color: #222;
    }

    .page {
      max-width: 1000px;
      margin: 0 auto;
      padding: 2rem 1.5rem 3rem;
    }

    a {
      color: #0070c9;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }

    /* ---------- Top navigation ---------- */
    .nav {
      display: flex;
      gap: 1.5rem;
      justify-content: flex-end;
      font-size: 0.9rem;
      margin-bottom: 1.5rem;
    }

    .nav a {
      text-transform: lowercase;
      letter-spacing: 0.08em;
    }

    .nav a.active {
      font-weight: 600;
    }

    /* ---------- Hero / header ---------- */
    .complete_header {
      display: flex;
      align-items: center;         /* vertically align hero + about text */
      justify-content: space-between;
      gap: 2rem;                   /* space between columns */
      margin-bottom: 3rem;
    }


    .hero {
      display: flex;
      flex-wrap: wrap;
      gap: 1.5rem;
      align-items: center;
      margin-bottom: 2rem;
      flex: 1 1 45%;
    }

    .hero-img {
      width: 140px;
      height: 140px;
      border-radius: 50%;
      background: #ddd;
      object-fit: cover;
      flex-shrink: 0;
    }

    .hero-main h1 {
      margin: 0 0 0.25rem 0;
      font-size: 1.75rem;
    }

    .hero-main h2 {
      margin: 0 0 0.5rem 0;
      font-size: 1rem;
      font-weight: 500;
      color: #555;
    }

    .hero-main .status-line {
      font-size: 0.9rem;
      color: #555;
      margin: 0.15rem 0;
    }

    .hero-main .contact {
      margin-top: 0.5rem;
      font-size: 0.9rem;
    }

    .hero-main .contact span {
      margin-right: 0.5rem;
    }

    #about {
      flex: 1 1 45%;
    }

    /* ---------- Section headings ---------- */
    section {
      margin-top: 2rem;
    }

    .section-title {
      font-size: 1.2rem;
      margin-bottom: 0.75rem;
      font-weight: 600;
    }

    /* Add a leading "#" like in markdown sites */
    .section-title::before {
      content: "# ";
      color: #999;
      font-weight: 400;
    }

    /* ---------- Text blocks ---------- */
    .about-text {
      max-width: 60ch;
      font-size: 0.98rem;
    }

    .entry {
      margin-bottom: 1.5rem;
    }

    .entry-title {
      font-size: 1rem;
      font-weight: 600;
      margin-bottom: 0.1rem;
    }

    .entry-meta {
      font-size: 0.85rem;
      color: #666;
      margin-bottom: 0.35rem;
    }

    .entry ul {
      margin: 0.25rem 0 0 1.25rem;
      padding: 0;
      font-size: 0.95rem;
    }

    .entry ul li + li {
      margin-top: 0.25rem;
    }

    /* ---------- News style (optional) ---------- */
    .news-item {
      margin-bottom: 0.6rem;
      font-size: 0.9rem;
    }

    .news-date {
      font-weight: 600;
      margin-right: 0.4rem;
    }

    /* ---------- Responsive tweaks ---------- */
    @media (max-width: 650px) {
      .nav {
        justify-content: center;
        flex-wrap: wrap;
      }
      .hero {
        justify-content: center;
        text-align: center;
      }
      .hero-main .contact {
        justify-content: center;
      }
    }
  </style>
</head>
<body>
  <div class="page">

    <!-- Top navigation -->
    <nav class="nav">
      <a href="#about">about</a>
      <a href="#research">research</a>
      <a href="#teaching">teaching</a>
      <a href="#projects">projects</a>
    </nav>

    <!-- Hero / header block -->
     <div class="complete_header">
      <header class="hero">
        <!-- Replace profile.jpg with your own photo file if you want -->
        <img src="profile.jpg" alt="Photo of Arnav Aggarwal" class="hero-img">

        <div class="hero-main">
          <h1>Arnav Aggarwal</h1>
          <h2>Computer Science (AI &amp; Decision Making) · Brain &amp; Cognitive Sciences @ MIT</h2>

          <p class="status-line"><strong>Currently:</strong> Doing research at the intersection of machine learning and neuroscience.</p>
          <p class="status-line">
            <strong>Previously:</strong> Machine Learning Intern @ LuxTronic · ErgOCR + LLMimic projects · TA for AI &amp; Rationality and Fundamentals of Programming.
          </p>

          <p class="contact">
            <span><a href="mailto:arnavxaggs@gmail.com">arnavxaggs@gmail.com</a></span> ·
            <span>Boston, MA</span> ·
            <span><a href="https://www.linkedin.com/in/arnavaggs/" target="_blank" rel="noopener noreferrer">LinkedIn</a></span>
            <!-- TODO: add your GitHub link below if you want -->
            <!-- · <span><a href="https://github.com/YOUR_USERNAME" target="_blank" rel="noopener noreferrer">GitHub</a></span> -->
          </p>
        </div>
      </header>

      <!-- About -->
      <section id="about">
        <h2 class="section-title">about me</h2>
        <p class="about-text">
          I’m an undergraduate at MIT studying Computer Science (AI &amp; Decision Making) with a minor in Brain and Cognitive Sciences. 
          I work at the intersection of machine learning and neuroscience, where I aim to develop specialized machine learning approaches 
          to help answer core neuroscience questions—particularly those related to how we process visual information.

          At the same time, I’m interested in using what we learn about human brain function and cognitive processes to build more 
          biologically realistic artificial systems. In particular, I’m drawn to models that can learn efficiently from limited data, 
          much like humans do, and that more faithfully capture the mechanisms underlying human perception.
          

        </p>
      </section>
    </div>

    <!-- Research -->
    <section id="research">
      <h2 class="section-title">research</h2>

      <div class="entry">
        <div class="entry-title">Reconstructing EEG from fMRI</div>
        <div class="entry-meta">Lewis Lab · MIT · 2025–present</div>
        <p>
          In this project, I have been developing neural network models to understand human brain activity. 
          Traditionally, electroencephalograms (EEGs) are best suited for capturing activity with high temporal resolution, 
          whereas functional magnetic resonance imaging (fMRI) is more effective at capturing activity with high spatial resolution. 
          However, these signals are generally noisy, and their relationship is complex. To overcome this, I utilized neural 
          networks to predict an EEG spectrogram from fMRI data, thereby modeling this relationship. I sucessfully used this model to 
          associate patterns of EEG activity with the specific brain regions responsible for them.
        </p>
      </div>

      <div class="entry">
        <div class="entry-title">Human-aligned speech perception models</div>
        <div class="entry-meta">Lab for Computational Audition (McDermott Lab) · MIT · 2025</div>
        <p>
          Humans exhibit a remarkable ability to understand speech across various speakers and noisy environments. While there has been 
          significant progress in building accurate speech recognition models, these models rely on architectures that do not reflect brain processes, 
          leading to behavior that diverges from human behavior. In this lab, I built a non-reccurent speech recognition model and compared its alignment with 
          human speech perception against reccurrent models. I found that non-recurrent models fail to reproduce patterns of human behavior compared to recurrent ones, 
          suggesting the importance of recurrence in human speech perception. I also examined the extent to which these models could 
          reproduce categorical perception. I discovered that the human-aligned speech recognition model showed the same unique 
          categorical perception pattern seen in humans. This work was published at the Association for Research in Otolaryngology (ARO). 
        </p>
      </div>
    </section>

    <!-- Projects / other work -->
    <section id="projects">
      <h2 class="section-title">projects</h2>

      <div class="entry">
        <div class="entry-title">ErgOCR – rowing machine workout transcription</div>
        <div class="entry-meta">Personal project · 2025</div>
        <p>
          In collegiate rowing, coxswains face a cumbersome and error-prone task of manually recording rowing machine (ergometer) scores, 
          often leading to inaccuracies potentially affecting athlete evaluation and boat placement. This project presents a computer vision 
          application designed to automate the extraction, aggregation, and recording of ergometer scores from images, thus improving efficiency 
          and accuracy compared with current manual efforts from coxswains. I achieved an accuracy of 99.5% of the scores in my test set. My developed 
          pipeline provides motivation for a broader range of OCR tasks on data stored in wireless tables. 
        </p>
      </div>

      <div class="entry">
        <div class="entry-title">LLMimic – personal writing style emulation</div>
        <div class="entry-meta">Personal project · 2024</div>
        <ul>
          <li>Combined fine-tuning and retrieval-augmented generation to better match a target author’s writing style.</li>
          <li>Designed an evaluation framework using authorship attribution and BLEU-style metrics to quantify stylistic alignment.</li>
        </ul>
      </div>

      <div class="entry">
        <div class="entry-title">Machine Learning Intern · LuxTronic</div>
        <div class="entry-meta">Remote · Summer 2024</div>
        <p>
          In my internship at LuxTronic, I worked on three main projects. (1) I upgraded object detection models to use 
          YOLOv10 that led to 5% (average) accuracy improvement on the most challenging customer datasets, while ensuring backward 
          compatibility for in-place upgrade. (2) I developed a CycleGAN to generate synthetic images of clear glass bottles from dark ones to 
          overcome the challenge of limited clear bottle data for model training. (3) I simplified client access to factory data by using GPT-4o 
          with RAG, allowing the clients to easily ask natural language queries and receive accuracte, comprehensible insights.
        </p>
      </div>
    </section>

    <!-- Teaching -->
    <section id="teaching">
      <h2 class="section-title">teaching</h2>

      <div class="entry">
        <div class="entry-title">Teaching Assistant · AI and Rationality</div>
        <div class="entry-meta">MIT · 2025</div>
        <ul>
          <li>Led office hours for a joint computer science and philosophy course, helping students with both technical problem sets and writing-based assignments.</li>
          <li>Trialed and reviewed homework and quiz problems, giving feedback to instructors on clarity and difficulty.</li>
        </ul>
      </div>

      <div class="entry">
        <div class="entry-title">Teaching Assistant · Fundamentals of Programming</div>
        <div class="entry-meta">MIT · 2024</div>
        <ul>
          <li>Guided students through debugging and designing solutions to medium-sized programming assignments in Python.</li>
          <li>Checked code for correctness, readability, and problem-solving strategy during office hours and checkoffs.</li>
        </ul>
      </div>
    </section>

    

  </div>
</body>
</html>
